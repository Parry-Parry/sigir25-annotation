{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotator Analysis for TREC Deep Learning Queries\n",
    "\n",
    "This notebook provides a simple data ingestion pipeline from which further analysis can be derived as a group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.0 has loaded Terrier 5.10 (built by craigm on 2024-08-22 17:33) and terrier-helper 0.0.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ir_measures import read_trec_qrels\n",
    "import ir_datasets as irds\n",
    "import pandas as pd\n",
    "import os\n",
    "import pyterrier as pt\n",
    "if not pt.started():\n",
    "    pt.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = '../..' # if this breaks replace with a full path to the repo\n",
    "\n",
    "DATASET = \"msmarco-passage/trec-dl-2019/judged\"\n",
    "qrel_directory = f'{DIR}/judgments/main/qrels/'\n",
    "annotation_directory = f'{DIR}/judgments/main/doccano/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = irds.load(DATASET)\n",
    "original_qrels = pd.DataFrame(dataset.qrels_iter())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "andrew-parry-qrels.txt\n",
      "ferdinand-schlatt-qrels.txt\n",
      "froebe-qrels.txt\n",
      "guglielmo-faggioli-qrels.txt\n",
      "harry-scells-qrels.txt\n",
      "saber-zerhoudi-qrels.txt\n",
      "sean-macavaney-qrels.txt\n",
      "eugene-yang-qrels.txt\n"
     ]
    }
   ],
   "source": [
    "all_qrels = []\n",
    "for file in os.listdir(qrel_directory):\n",
    "    print(file)\n",
    "    if file.endswith('.txt'):\n",
    "        qrels = pd.DataFrame(read_trec_qrels(qrel_directory + file))\n",
    "        annotator = file.replace('.txt', '').replace('-qrels', '')\n",
    "        qrels['annotator'] = annotator\n",
    "        all_qrels.append(qrels)\n",
    "\n",
    "all_qrels = pd.concat(all_qrels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>relevance</th>\n",
       "      <th>iteration</th>\n",
       "      <th>annotator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>855410</td>\n",
       "      <td>8651770</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>andrew-parry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>855410</td>\n",
       "      <td>8651771</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>andrew-parry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>855410</td>\n",
       "      <td>8651772</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>andrew-parry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>855410</td>\n",
       "      <td>8651775</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>andrew-parry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>146187</td>\n",
       "      <td>1230566</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>andrew-parry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>1114646</td>\n",
       "      <td>3915244</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>eugene-yang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>168216</td>\n",
       "      <td>4713638</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>eugene-yang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>168216</td>\n",
       "      <td>1696466</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>eugene-yang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>168216</td>\n",
       "      <td>4245224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>eugene-yang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>168216</td>\n",
       "      <td>3174832</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>eugene-yang</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9004 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     query_id   doc_id  relevance iteration     annotator\n",
       "0      855410  8651770          2         0  andrew-parry\n",
       "1      855410  8651771          2         0  andrew-parry\n",
       "2      855410  8651772          1         0  andrew-parry\n",
       "3      855410  8651775          3         0  andrew-parry\n",
       "4      146187  1230566          1         0  andrew-parry\n",
       "...       ...      ...        ...       ...           ...\n",
       "1110  1114646  3915244          0         0   eugene-yang\n",
       "1111   168216  4713638          0         0   eugene-yang\n",
       "1112   168216  1696466          0         0   eugene-yang\n",
       "1113   168216  4245224          0         0   eugene-yang\n",
       "1114   168216  3174832          0         0   eugene-yang\n",
       "\n",
       "[9004 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each query, doc pair take the max relevance score\n",
    "max_qrels = all_qrels.groupby(['query_id', 'doc_id']).agg({'relevance': 'max'}).reset_index()\n",
    "min_qrels = all_qrels.groupby(['query_id', 'doc_id']).agg({'relevance': 'min'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1037798</td>\n",
       "      <td>184064</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1037798</td>\n",
       "      <td>2157456</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1037798</td>\n",
       "      <td>2970896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1037798</td>\n",
       "      <td>3167284</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1037798</td>\n",
       "      <td>3387556</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4506</th>\n",
       "      <td>962179</td>\n",
       "      <td>6898290</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4507</th>\n",
       "      <td>962179</td>\n",
       "      <td>6980697</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4508</th>\n",
       "      <td>962179</td>\n",
       "      <td>8785367</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4509</th>\n",
       "      <td>962179</td>\n",
       "      <td>8785370</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4510</th>\n",
       "      <td>962179</td>\n",
       "      <td>8785371</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4511 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     query_id   doc_id  relevance\n",
       "0     1037798   184064          0\n",
       "1     1037798  2157456          0\n",
       "2     1037798  2970896          0\n",
       "3     1037798  3167284          2\n",
       "4     1037798  3387556          2\n",
       "...       ...      ...        ...\n",
       "4506   962179  6898290          0\n",
       "4507   962179  6980697          2\n",
       "4508   962179  8785367          1\n",
       "4509   962179  8785370          0\n",
       "4510   962179  8785371          3\n",
       "\n",
       "[4511 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>relevance</th>\n",
       "      <th>iteration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19335</td>\n",
       "      <td>1017759</td>\n",
       "      <td>0</td>\n",
       "      <td>Q0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19335</td>\n",
       "      <td>1082489</td>\n",
       "      <td>0</td>\n",
       "      <td>Q0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19335</td>\n",
       "      <td>109063</td>\n",
       "      <td>0</td>\n",
       "      <td>Q0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19335</td>\n",
       "      <td>1160863</td>\n",
       "      <td>0</td>\n",
       "      <td>Q0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19335</td>\n",
       "      <td>1160871</td>\n",
       "      <td>0</td>\n",
       "      <td>Q0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9255</th>\n",
       "      <td>1133167</td>\n",
       "      <td>8839920</td>\n",
       "      <td>2</td>\n",
       "      <td>Q0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9256</th>\n",
       "      <td>1133167</td>\n",
       "      <td>8839922</td>\n",
       "      <td>2</td>\n",
       "      <td>Q0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9257</th>\n",
       "      <td>1133167</td>\n",
       "      <td>944810</td>\n",
       "      <td>0</td>\n",
       "      <td>Q0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9258</th>\n",
       "      <td>1133167</td>\n",
       "      <td>949411</td>\n",
       "      <td>0</td>\n",
       "      <td>Q0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9259</th>\n",
       "      <td>1133167</td>\n",
       "      <td>977421</td>\n",
       "      <td>0</td>\n",
       "      <td>Q0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9260 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     query_id   doc_id  relevance iteration\n",
       "0       19335  1017759          0        Q0\n",
       "1       19335  1082489          0        Q0\n",
       "2       19335   109063          0        Q0\n",
       "3       19335  1160863          0        Q0\n",
       "4       19335  1160871          0        Q0\n",
       "...       ...      ...        ...       ...\n",
       "9255  1133167  8839920          2        Q0\n",
       "9256  1133167  8839922          2        Q0\n",
       "9257  1133167   944810          0        Q0\n",
       "9258  1133167   949411          0        Q0\n",
       "9259  1133167   977421          0        Q0\n",
       "\n",
       "[9260 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the original qrels with the max qrels on query_id and doc_id to compare relevance values\n",
    "joined = original_qrels.merge(max_qrels, on=['query_id', 'doc_id'], suffixes=('_original', '_max'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>relevance_original</th>\n",
       "      <th>iteration</th>\n",
       "      <th>relevance_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19335</td>\n",
       "      <td>1231807</td>\n",
       "      <td>0</td>\n",
       "      <td>Q0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19335</td>\n",
       "      <td>1720389</td>\n",
       "      <td>1</td>\n",
       "      <td>Q0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19335</td>\n",
       "      <td>1720395</td>\n",
       "      <td>1</td>\n",
       "      <td>Q0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19335</td>\n",
       "      <td>1729</td>\n",
       "      <td>2</td>\n",
       "      <td>Q0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19335</td>\n",
       "      <td>1837110</td>\n",
       "      <td>0</td>\n",
       "      <td>Q0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4506</th>\n",
       "      <td>1133167</td>\n",
       "      <td>8804478</td>\n",
       "      <td>1</td>\n",
       "      <td>Q0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4507</th>\n",
       "      <td>1133167</td>\n",
       "      <td>8839919</td>\n",
       "      <td>1</td>\n",
       "      <td>Q0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4508</th>\n",
       "      <td>1133167</td>\n",
       "      <td>8839920</td>\n",
       "      <td>2</td>\n",
       "      <td>Q0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4509</th>\n",
       "      <td>1133167</td>\n",
       "      <td>8839922</td>\n",
       "      <td>2</td>\n",
       "      <td>Q0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4510</th>\n",
       "      <td>1133167</td>\n",
       "      <td>944810</td>\n",
       "      <td>0</td>\n",
       "      <td>Q0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4511 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     query_id   doc_id  relevance_original iteration  relevance_max\n",
       "0       19335  1231807                   0        Q0              0\n",
       "1       19335  1720389                   1        Q0              0\n",
       "2       19335  1720395                   1        Q0              0\n",
       "3       19335     1729                   2        Q0              0\n",
       "4       19335  1837110                   0        Q0              0\n",
       "...       ...      ...                 ...       ...            ...\n",
       "4506  1133167  8804478                   1        Q0              2\n",
       "4507  1133167  8839919                   1        Q0              0\n",
       "4508  1133167  8839920                   2        Q0              1\n",
       "4509  1133167  8839922                   2        Q0              3\n",
       "4510  1133167   944810                   0        Q0              0\n",
       "\n",
       "[4511 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments = []\n",
    "for file in os.listdir(annotation_directory):\n",
    "    if file.endswith('.jsonl'):\n",
    "        comments = pd.read_json(annotation_directory + file, lines=True)\n",
    "        annotator = file.replace('.jsonl', '')\n",
    "        comments['annotator'] = annotator\n",
    "        # filter in case that comments 'Comments' column is an empty list\n",
    "        comments = comments[comments['Comments'].apply(lambda x: len(x) > 0)]\n",
    "        all_comments.append(comments)\n",
    "\n",
    "all_comments = pd.concat(all_comments)[['text', 'annotator', 'label', 'Comments']]\n",
    "all_comments['label'] = all_comments['label'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>annotator</th>\n",
       "      <th>label</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gas. For hydrogen to become a liquid, you need...</td>\n",
       "      <td>froebe</td>\n",
       "      <td>Perfectly Relevant (3)</td>\n",
       "      <td>[Description: What is the temperature in degre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Definitions for Contour plowing. Here are all ...</td>\n",
       "      <td>froebe</td>\n",
       "      <td>Not Relevant (0)</td>\n",
       "      <td>[A user is in a discussion about farming pract...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>The sides AC and BD above are called the legs ...</td>\n",
       "      <td>froebe</td>\n",
       "      <td>Not Relevant (0)</td>\n",
       "      <td>[Description:\\nI have trapezoid in front of me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Pseudobulbar palsy is characterized by the ina...</td>\n",
       "      <td>froebe</td>\n",
       "      <td>Not Relevant (0)</td>\n",
       "      <td>[Description:\\nI know that dysarthria can be c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>Left Ventricular Hypertrophy. Left Ventricular...</td>\n",
       "      <td>froebe</td>\n",
       "      <td>Not Relevant (0)</td>\n",
       "      <td>[Description:\\nWhat factors can contribute to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>You might be interested to know that both the ...</td>\n",
       "      <td>froebe</td>\n",
       "      <td>Relevant (1)</td>\n",
       "      <td>[Description:\\nI am a nurse and already hold m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>Genera such as Rhynia have a similar life-cycl...</td>\n",
       "      <td>froebe</td>\n",
       "      <td>Not Relevant (0)</td>\n",
       "      <td>[Description: tracheids are part of which tiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>After about 2 days (range 2-21 days), dependin...</td>\n",
       "      <td>froebe</td>\n",
       "      <td>Not Relevant (0)</td>\n",
       "      <td>[Description:\\nHow long is the complete life c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>Deadly: A conceptual image of Legionella Pneum...</td>\n",
       "      <td>froebe</td>\n",
       "      <td>Not Relevant (0)</td>\n",
       "      <td>[Description:\\nI am in a discussion with a fri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rösti (ˈrɜːstɪ) or rosti n (Cookery) a Swiss d...</td>\n",
       "      <td>guglielmo-faggioli</td>\n",
       "      <td>Relevant (1)</td>\n",
       "      <td>[This document, in my opinion, would be releva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>For example, Switzerland is famous for its not...</td>\n",
       "      <td>guglielmo-faggioli</td>\n",
       "      <td>Relevant (1)</td>\n",
       "      <td>[I think this document perfectly summarizes my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>on average getting concrete floors can cost an...</td>\n",
       "      <td>guglielmo-faggioli</td>\n",
       "      <td>Relevant (1)</td>\n",
       "      <td>[a lot of the documents are exactly the same.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>However, it can lead to pneumonia, a serious l...</td>\n",
       "      <td>guglielmo-faggioli</td>\n",
       "      <td>Not Relevant (0)</td>\n",
       "      <td>[I'm not sure what \"it\" refers to]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Paris has two large international airports, Or...</td>\n",
       "      <td>saber-zerhoudi</td>\n",
       "      <td>Highly Relevant (2)</td>\n",
       "      <td>[A passage is perfectly relevant (3) if it eit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>To show that it does indeed have a limit, we'l...</td>\n",
       "      <td>saber-zerhoudi</td>\n",
       "      <td>Relevant (1)</td>\n",
       "      <td>[A passage is perfectly relevant (3) if it pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>A Tornado Watch is issued by the Storm Predict...</td>\n",
       "      <td>saber-zerhoudi</td>\n",
       "      <td>Relevant (1)</td>\n",
       "      <td>[A passage is perfectly relevant (3) if it pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Spruce. Picea. Holding their dense branches al...</td>\n",
       "      <td>saber-zerhoudi</td>\n",
       "      <td>Relevant (1)</td>\n",
       "      <td>[A passage is perfectly relevant (3) if it pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>An LPS Conservatorship is a court proceeding t...</td>\n",
       "      <td>saber-zerhoudi</td>\n",
       "      <td>Perfectly Relevant (3)</td>\n",
       "      <td>[A passage is perfectly relevant (3) if it dir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>Convergent boundaries (Destructive) (or active...</td>\n",
       "      <td>saber-zerhoudi</td>\n",
       "      <td>Highly Relevant (2)</td>\n",
       "      <td>[A passage is perfectly relevant (3) if it dir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>The flag of the Kingdom of Thailand (Thai: ธงไ...</td>\n",
       "      <td>saber-zerhoudi</td>\n",
       "      <td>Not Relevant (0)</td>\n",
       "      <td>[If the passage contains information about the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>The immediate cause of the United States’ entr...</td>\n",
       "      <td>saber-zerhoudi</td>\n",
       "      <td>Highly Relevant (2)</td>\n",
       "      <td>[A passage is perfectly relevant (3) if it con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>In 1912, Arizona became the 48th state with Ph...</td>\n",
       "      <td>saber-zerhoudi</td>\n",
       "      <td>Highly Relevant (2)</td>\n",
       "      <td>[The passage is considered as a High relevant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>112 Garibaldi Ave, Garibaldi, Oregon 97118, ph...</td>\n",
       "      <td>saber-zerhoudi</td>\n",
       "      <td>Not Relevant (0)</td>\n",
       "      <td>[Relevant passages contain information about t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>The vagus nerve is either one of two cranial n...</td>\n",
       "      <td>saber-zerhoudi</td>\n",
       "      <td>Highly Relevant (2)</td>\n",
       "      <td>[A passage is perfectly relevant (3) if it pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>Why did the United States enter WWII? The Unit...</td>\n",
       "      <td>saber-zerhoudi</td>\n",
       "      <td>Not Relevant (0)</td>\n",
       "      <td>[Not relevant- Rare case of WWII instead of WWI]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The main ingredient in this Theraderm cream is...</td>\n",
       "      <td>eugene-yang</td>\n",
       "      <td>Not Relevant (0)</td>\n",
       "      <td>[Theraderm in the doc is using as a different ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Theraderm Skin Renewal System. Theraderm Skin ...</td>\n",
       "      <td>eugene-yang</td>\n",
       "      <td>Not Relevant (0)</td>\n",
       "      <td>[This is tricky. Depending on whether you know...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text           annotator  \\\n",
       "0     Gas. For hydrogen to become a liquid, you need...              froebe   \n",
       "28    Definitions for Contour plowing. Here are all ...              froebe   \n",
       "74    The sides AC and BD above are called the legs ...              froebe   \n",
       "130   Pseudobulbar palsy is characterized by the ina...              froebe   \n",
       "205   Left Ventricular Hypertrophy. Left Ventricular...              froebe   \n",
       "288   You might be interested to know that both the ...              froebe   \n",
       "389   Genera such as Rhynia have a similar life-cycl...              froebe   \n",
       "738   After about 2 days (range 2-21 days), dependin...              froebe   \n",
       "1026  Deadly: A conceptual image of Legionella Pneum...              froebe   \n",
       "14    rösti (ˈrɜːstɪ) or rosti n (Cookery) a Swiss d...  guglielmo-faggioli   \n",
       "36    For example, Switzerland is famous for its not...  guglielmo-faggioli   \n",
       "342   on average getting concrete floors can cost an...  guglielmo-faggioli   \n",
       "1134  However, it can lead to pneumonia, a serious l...  guglielmo-faggioli   \n",
       "1     Paris has two large international airports, Or...      saber-zerhoudi   \n",
       "87    To show that it does indeed have a limit, we'l...      saber-zerhoudi   \n",
       "151   A Tornado Watch is issued by the Storm Predict...      saber-zerhoudi   \n",
       "228   Spruce. Picea. Holding their dense branches al...      saber-zerhoudi   \n",
       "322   An LPS Conservatorship is a court proceeding t...      saber-zerhoudi   \n",
       "323   Convergent boundaries (Destructive) (or active...      saber-zerhoudi   \n",
       "442   The flag of the Kingdom of Thailand (Thai: ธงไ...      saber-zerhoudi   \n",
       "585   The immediate cause of the United States’ entr...      saber-zerhoudi   \n",
       "704   In 1912, Arizona became the 48th state with Ph...      saber-zerhoudi   \n",
       "860   112 Garibaldi Ave, Garibaldi, Oregon 97118, ph...      saber-zerhoudi   \n",
       "964   The vagus nerve is either one of two cranial n...      saber-zerhoudi   \n",
       "1078  Why did the United States enter WWII? The Unit...      saber-zerhoudi   \n",
       "1     The main ingredient in this Theraderm cream is...         eugene-yang   \n",
       "3     Theraderm Skin Renewal System. Theraderm Skin ...         eugene-yang   \n",
       "\n",
       "                       label  \\\n",
       "0     Perfectly Relevant (3)   \n",
       "28          Not Relevant (0)   \n",
       "74          Not Relevant (0)   \n",
       "130         Not Relevant (0)   \n",
       "205         Not Relevant (0)   \n",
       "288             Relevant (1)   \n",
       "389         Not Relevant (0)   \n",
       "738         Not Relevant (0)   \n",
       "1026        Not Relevant (0)   \n",
       "14              Relevant (1)   \n",
       "36              Relevant (1)   \n",
       "342             Relevant (1)   \n",
       "1134        Not Relevant (0)   \n",
       "1        Highly Relevant (2)   \n",
       "87              Relevant (1)   \n",
       "151             Relevant (1)   \n",
       "228             Relevant (1)   \n",
       "322   Perfectly Relevant (3)   \n",
       "323      Highly Relevant (2)   \n",
       "442         Not Relevant (0)   \n",
       "585      Highly Relevant (2)   \n",
       "704      Highly Relevant (2)   \n",
       "860         Not Relevant (0)   \n",
       "964      Highly Relevant (2)   \n",
       "1078        Not Relevant (0)   \n",
       "1           Not Relevant (0)   \n",
       "3           Not Relevant (0)   \n",
       "\n",
       "                                               Comments  \n",
       "0     [Description: What is the temperature in degre...  \n",
       "28    [A user is in a discussion about farming pract...  \n",
       "74    [Description:\\nI have trapezoid in front of me...  \n",
       "130   [Description:\\nI know that dysarthria can be c...  \n",
       "205   [Description:\\nWhat factors can contribute to ...  \n",
       "288   [Description:\\nI am a nurse and already hold m...  \n",
       "389   [Description: tracheids are part of which tiss...  \n",
       "738   [Description:\\nHow long is the complete life c...  \n",
       "1026  [Description:\\nI am in a discussion with a fri...  \n",
       "14    [This document, in my opinion, would be releva...  \n",
       "36    [I think this document perfectly summarizes my...  \n",
       "342   [a lot of the documents are exactly the same.....  \n",
       "1134                 [I'm not sure what \"it\" refers to]  \n",
       "1     [A passage is perfectly relevant (3) if it eit...  \n",
       "87    [A passage is perfectly relevant (3) if it pro...  \n",
       "151   [A passage is perfectly relevant (3) if it pro...  \n",
       "228   [A passage is perfectly relevant (3) if it pro...  \n",
       "322   [A passage is perfectly relevant (3) if it dir...  \n",
       "323   [A passage is perfectly relevant (3) if it dir...  \n",
       "442   [If the passage contains information about the...  \n",
       "585   [A passage is perfectly relevant (3) if it con...  \n",
       "704   [The passage is considered as a High relevant ...  \n",
       "860   [Relevant passages contain information about t...  \n",
       "964   [A passage is perfectly relevant (3) if it pro...  \n",
       "1078   [Not relevant- Rare case of WWII instead of WWI]  \n",
       "1     [Theraderm in the doc is using as a different ...  \n",
       "3     [This is tricky. Depending on whether you know...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_lookup = all_comments[['query', 'query_id']].drop_duplicates().set_index('query_id')['query'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "required = all_qrels['query_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np \n",
    "from sklearn import metrics\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "class TrecQrel:\n",
    "    def __init__(self, filename=None, qrels_header=[\"query\",\"q0\",\"docid\",\"rel\"]):\n",
    "\n",
    "        #TODO: support to check whether the fields match.\n",
    "        if filename:\n",
    "            self.read_qrel(filename, qrels_header)\n",
    "        else:\n",
    "            self.filename = None\n",
    "            self.qrels_data = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "    def __str__(self):\n",
    "        if self.filename:\n",
    "            return \"Data from file %s\" % (self.get_full_filename_path())\n",
    "        else:\n",
    "            return \"Data file not set yet\"\n",
    "\n",
    "    def __filter_topics(self, df, topics):\n",
    "        if type(topics) is list:\n",
    "            topics = set(topics)\n",
    "        if type(topics) is not set:\n",
    "            print(\"ERROR: topics should be a set\")\n",
    "            return None\n",
    "        return df[df[\"query\"].apply(lambda x: x in topics)]\n",
    "\n",
    "    def print_subset(self, filename, topics=None, labels=None, another_qrel=None):\n",
    "        \"\"\"\n",
    "            Creates a new qrel with name 'filename' based on the selected topics or labels.\n",
    "\n",
    "            A common use case is to have all documents that appear in another qrel. For that,\n",
    "            use 'another_qrel' parameter.\n",
    "        \"\"\"\n",
    "\n",
    "        if another_qrel is None and labels is None and topics is None:\n",
    "            print(\"You should assign a set of labels, topics or at least input another qrel to be filtered.\")\n",
    "            return\n",
    "\n",
    "        dslice = None\n",
    "        if topics is not None and labels is None:\n",
    "            dslice = self.qrels_data[self.qrels_data[\"query\"].apply(lambda x: x in set(topics))]\n",
    "        elif labels is not None and topics is None:\n",
    "            dslice = self.qrels_data[self.qrels_data[\"rel\"].apply(lambda x: x in set(labels))]\n",
    "        elif labels is not None and topics is not None:\n",
    "            dslice = self.qrels_data[(self.qrels_data[\"query\"].apply(lambda x: x in set(topics))) &\n",
    "                    (self.qrels_data[\"rel\"].apply(lambda x: x in set(labels)))]\n",
    "\n",
    "        if another_qrel:\n",
    "            if dslice is None:\n",
    "                dslice = self.qrels_data.copy()\n",
    "            dslice = pd.merge(dslice, another_qrel.qrels_data, on=[\"query\",\"q0\",\"docid\"])\n",
    "            dslice[\"rel\"] = dslice[\"rel_x\"]\n",
    "            del dslice[\"rel_y\"]\n",
    "            del dslice[\"rel_x\"]\n",
    "\n",
    "        dslice[[\"query\", \"q0\", \"docid\", \"rel\"]].to_csv(filename, sep=\" \", header=False, index=False)\n",
    "        print(\"File %s writen.\" % (filename))\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataframe(cls, df):\n",
    "        \"\"\"\n",
    "            Create a TrecQrel object from a pandas dataframe.\n",
    "        \"\"\"\n",
    "        t = TrecQrel()\n",
    "        t.qrels_data = df.rename(columns={\"query_id\":\"query\",\"doc_id\":\"docid\",\"relevance\":\"rel\", 'iteration':'q0'})[[\"query\",\"q0\",\"docid\",\"rel\"]]\n",
    "        return t\n",
    "\n",
    "    def read_qrel(self, filename, qrels_header=None):\n",
    "        # Replace with default argument for qrel_header\n",
    "        if qrels_header is None:\n",
    "            qrels_header = [\"query\", \"q0\", \"docid\", \"rel\"]\n",
    "\n",
    "        # Set filename\n",
    "        self.filename = filename\n",
    "\n",
    "        # Read data from file\n",
    "        self.qrels_data = pd.read_csv(filename, sep=\"\\s+\", names=qrels_header)\n",
    "\n",
    "        # Enforce string type on docid column (if present)\n",
    "        if \"docid\" in self.qrels_data:\n",
    "            self.qrels_data[\"docid\"] = self.qrels_data[\"docid\"].astype(str)\n",
    "        # Enforce string type on q0 column (if present)\n",
    "        if \"q0\" in self.qrels_data:\n",
    "            self.qrels_data[\"q0\"] = self.qrels_data[\"q0\"].astype(str)\n",
    "        # Enforce string type on query column (if present)\n",
    "        if \"query\" in self.qrels_data:\n",
    "            self.qrels_data[\"query\"] = self.qrels_data[\"query\"].astype(str)\n",
    "\n",
    "        # Removes the files that were not judged:\n",
    "        self.qrels_data = self.qrels_data[self.qrels_data[\"rel\"] >= 0]\n",
    "\n",
    "    def compare_with(self, another_qrel, topics=None):\n",
    "        \"\"\"\n",
    "            Compare two qrels for a given set of topics.\n",
    "            Returns means and checks for statistical significant differences.\n",
    "            Only compares documents that are available in both sets.\n",
    "            Use 'topics' parameter if you want to filter even further.\n",
    "        \"\"\"\n",
    "        if topics is not None:\n",
    "            dslice = self.__filter_topics(self.qrels_data, topics)\n",
    "            oslice = self.__filter_topics(another_qrel.qrels_data, topics)\n",
    "        else:\n",
    "            dslice = self.qrels_data\n",
    "            oslice = another_qrel.qrels_data\n",
    "\n",
    "        merged = pd.merge(dslice, oslice, on=[\"query\",\"q0\",\"docid\"])\n",
    "        a = merged[\"rel_x\"]\n",
    "        b = merged[\"rel_y\"]\n",
    "        s, p = ttest_ind(a,b)\n",
    "        print(\"This:  %.2f - %.2f\" % (a.mean(), a.std()))\n",
    "        print(\"Other: %.2f - %.2f\" % (b.mean(), b.std()))\n",
    "        print(\"significance: \", p)\n",
    "        print(\"number of examples: \", a.shape[0])\n",
    "        return (a.mean(), a.std(), b.mean(), b.std(), p, a.shape[0])\n",
    "\n",
    "    def describe(self, topics=None):\n",
    "        if topics is not None:\n",
    "            dslice = self.__filter_topics(self.qrels_data, topics)\n",
    "            if dslice is not None:\n",
    "                return dslice[\"rel\"].describe()\n",
    "        else:\n",
    "            return self.qrels_data[\"rel\"].describe()\n",
    "\n",
    "    def topics(self):\n",
    "        return set(self.qrels_data[\"query\"].unique())\n",
    "\n",
    "    def topics_intersection_with(self, another_qrel):\n",
    "        return self.topics().intersection(another_qrel.topics())\n",
    "\n",
    "    def fill_up(self, another_qrel):\n",
    "        \"\"\"\n",
    "            Complete the judgments for topics that have no judgement yet. It does not change anything in topics that have\n",
    "            already some judgment.\n",
    "        \"\"\"\n",
    "        new_topics = another_qrel.topics() - self.topics()\n",
    "        for topic in new_topics:\n",
    "            new_data = another_qrel.qrels_data[another_qrel.qrels_data[\"query\"] == topic]\n",
    "            self.qrels_data = pd.concat((self.qrels_data,new_data))\n",
    "            logging.warning(\"Added topic %s\" % str(topic))\n",
    "\n",
    "    def get_full_filename_path(self):\n",
    "        return os.path.abspath(os.path.expanduser(self.filename))\n",
    "\n",
    "    def get_filename(self):\n",
    "        return os.path.basename(self.get_full_filename_path())\n",
    "\n",
    "    def get_number_of(self, label, topics=None):\n",
    "        if topics is not None:\n",
    "            dslice = self.qrels_data[self.qrels_data[\"query\"].apply(lambda x: x in set(topics))]\n",
    "            return (dslice[\"rel\"] == label).sum()\n",
    "        else:\n",
    "            return (self.qrels_data[\"rel\"] == label).sum()\n",
    "\n",
    "    def check_kappa(self, another_qrel):\n",
    "        \"\"\"\n",
    "            Kappa coeficient for binary data only.\n",
    "        \"\"\"\n",
    "        # TODO: check if there are only two categories.\n",
    "        r = pd.merge(self.qrels_data, another_qrel.qrels_data, on=[\"query\",\"q0\",\"docid\"]) # TODO: rename fields as done in trec_res\n",
    "        a, b = r[\"rel_x\"], r[\"rel_y\"]\n",
    "        p0 = 1. * (a == b).sum() / a.shape[0]\n",
    "        a_true_percentage = 1. * a.sum() / a.shape[0]\n",
    "        b_true_percentage = 1. * b.sum() / b.shape[0]\n",
    "        pe = (a_true_percentage * b_true_percentage) + ((1. - a_true_percentage) * (1. - b_true_percentage))\n",
    "        print(\"P0: %.2f, Pe = %.2f\" % (p0, pe))\n",
    "        return (p0 - pe) / (1.0 - pe)\n",
    "\n",
    "    def check_overlap(self, another_qrel, min_rel_label=1):\n",
    "        r = pd.merge(self.qrels_data, another_qrel.qrels_data, on=[\"query\",\"q0\",\"docid\"]) # TODO: rename fields as done in trec_res\n",
    "        intersection = r[(r[\"rel_x\"] >= min_rel_label) & (r[\"rel_y\"] >= min_rel_label)]\n",
    "        union = r[(r[\"rel_x\"] >= min_rel_label) | (r[\"rel_y\"] >= min_rel_label)]\n",
    "        return 1. * intersection.shape[0] / union.shape[0]\n",
    "\n",
    "    def check_jaccard(self, another_qrel, topics=None):\n",
    "        # TODO\n",
    "        pass\n",
    "\n",
    "    def check_confusion_matrix(self, another_qrel, topics=None, labels=None):\n",
    "        \"\"\"\n",
    "            Returns a confusion matrix for the topics that this qrel and another_qrel have in common.\n",
    "            Use the paramenters topics and labels to restrict even more the topics and labels shown.\n",
    "        \"\"\"\n",
    "        r = pd.merge(self.qrels_data, another_qrel.qrels_data, on=[\"query\",\"q0\",\"docid\"]) # TODO: rename fields as done in trec_res\n",
    "        if topics:\n",
    "            r = self.__filter_topics(r, topics)\n",
    "            if r is None:\n",
    "                print(\"ERROR in filtering topics\")\n",
    "                return None\n",
    "            print(\"Resulting topics being used: \", r[\"query\"].unique())\n",
    "        return metrics.confusion_matrix(r[\"rel_x\"], r[\"rel_y\"], labels=labels)\n",
    "\n",
    "    def explore_agreement(self, another_qrel, topic):\n",
    "        \"\"\"\n",
    "            Giving another set of relevance assessments and a topic, it returns for each document whether or not an agreement was found.\n",
    "        \"\"\"\n",
    "        slice1 = self.qrels_data[self.qrels_data[\"query\"] == topic]\n",
    "        slice2 = another_qrel.qrels_data[another_qrel.qrels_data[\"query\"] == topic]\n",
    "\n",
    "        return pd.merge(slice1, slice2, on=[\"query\",\"q0\",\"docid\"])\n",
    "\n",
    "    def check_agreement(self, another_qrel, topics=None, labels=None):\n",
    "\n",
    "        if labels is not None:\n",
    "            #TODO: add support for filtering some labels\n",
    "            print(\"SORRY LABEL SUPPORT NOT IMPLEMENTED YET\")\n",
    "            return None\n",
    "\n",
    "        r = pd.merge(self.qrels_data, another_qrel.qrels_data, on=[\"query\",\"q0\",\"docid\"]) # TODO: rename fields as done in trec_res\n",
    "\n",
    "        if r.shape[0] == 0:\n",
    "            print(\"No registers in common\")\n",
    "            return np.nan\n",
    "\n",
    "        if topics:\n",
    "            agreements = {}\n",
    "            for topic in topics:\n",
    "                rt = r[r[\"query\"] == topic]\n",
    "                if rt.shape[0] == 0:\n",
    "                    print(\"ERROR: invalid topic:\", topic)\n",
    "                    agreements[topic] = np.nan\n",
    "                    continue\n",
    "\n",
    "                agreements[topic] = 1.0 * (rt[\"rel_x\"] == rt[\"rel_y\"]).sum() / rt.shape[0]\n",
    "            return agreements\n",
    "\n",
    "        return 1.0 * (r[\"rel_x\"] == r[\"rel_y\"]).sum() / r.shape[0]\n",
    "\n",
    "    def pairwise_matrix(self, another_qrel):\n",
    "        r = pd.merge(self.qrels_data, another_qrel.qrels_data, on=[\"query\",\"q0\",\"docid\"])\n",
    "        m = np.zeros((3,3))\n",
    "        def fmap(a,b):\n",
    "            if a < b:\n",
    "                return 0\n",
    "            elif a == b:\n",
    "                return 1\n",
    "            return 2\n",
    "        for t in r[\"query\"].unique():\n",
    "            tslice = r[r[\"query\"] == t]\n",
    "            vs = tslice[[\"docid\",\"rel_x\", \"rel_y\"]].values\n",
    "            for i in range(vs.shape[0]):\n",
    "                for j in range(i, vs.shape[0]):\n",
    "                    m[fmap(vs[i][1],vs[i][2])][fmap(vs[j][1],vs[j][2])] += 1\n",
    "\n",
    "        print(\"Pairwise Agreement: %.2f \" % (1.* (m[0][0] + m[1][1] + m[2][2]) / m.sum()))\n",
    "        print(\"Total Disagement: %.2f \" % (1.* (m[0][2] + m[2][0]) / m.sum()))\n",
    "        return m\n",
    "\n",
    "    def merge_with(self, another_qrel, operation=\"or\", keep_all=False, filename=None):\n",
    "\n",
    "        if keep_all:\n",
    "            r = pd.merge(self.qrels_data, another_qrel.qrels_data, on=[\"query\",\"q0\",\"docid\"], how=\"outer\")\n",
    "            r.fillna(-1, inplace=True)\n",
    "            r[\"q0\"] = r[\"q0\"].astype(int)\n",
    "            # TODO: not desirable as this will limit the queries to be integer\n",
    "            r[\"query\"] = r[\"query\"].astype(int)\n",
    "\n",
    "        else:\n",
    "            r = pd.merge(self.qrels_data, another_qrel.qrels_data, on=[\"query\",\"q0\",\"docid\"])\n",
    "\n",
    "        if operation == \"or\":\n",
    "            r[\"rel\"] = r[[\"rel_x\", \"rel_y\"]].apply(max, axis=1)\n",
    "        elif operation == \"and\":\n",
    "            r[\"rel\"] = r[[\"rel_x\", \"rel_y\"]].apply(min, axis=1)\n",
    "        else:\n",
    "            print(\"ERROR: No such operation %s. Options are 'or', 'and'.\" % (operation))\n",
    "            return None\n",
    "\n",
    "        if keep_all:\n",
    "            r[\"rel\"] = np.where(r[\"rel_y\"] < 0, r[\"rel_x\"], r[\"rel\"])\n",
    "            r[\"rel\"] = np.where(r[\"rel_x\"] < 0, r[\"rel_y\"], r[\"rel\"])\n",
    "\n",
    "        r[\"rel\"] = r[\"rel\"].astype(int)\n",
    "\n",
    "        if filename:\n",
    "            r[[\"query\", \"q0\", \"docid\", \"rel\"]].to_csv(filename, sep=\" \", header=False, index=False)\n",
    "            print(\"File %s writen.\" % (filename))\n",
    "\n",
    "        return TrecQrel.from_dataframe(r[[\"query\", \"q0\", \"docid\", \"rel\"]])\n",
    "\n",
    "    def get_judgement(self, document, topic):\n",
    "        \"\"\"\n",
    "        Returns \"rel\" value if the pair document-topic is found.\n",
    "        Else, returns -1.\n",
    "        \"\"\"\n",
    "        returned = self.qrels_data.loc[(self.qrels_data[\"docid\"] == document) & (self.qrels_data[\"query\"] == topic)]\n",
    "        if returned.shape[0] > 1:\n",
    "            print(\"ERROR: more than one value returned.\")\n",
    "            return returned\n",
    "        elif returned.shape[0] == 1:\n",
    "            return returned[\"rel\"].values[0]\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    def get_document_names_for_topic(self, topicX):\n",
    "        \"\"\"\n",
    "            return a set with the names of all documents judged for topic X.\n",
    "        \"\"\"\n",
    "        return set(self.qrels_data[self.qrels_data[\"query\"] == topicX][\"docid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def compute_qrel_confusion_matrices(qrel_list, topics=None, labels=None):\n",
    "    \"\"\"\n",
    "    Compute confusion matrices for all combinations of qrel objects in the list.\n",
    "    \n",
    "    Args:\n",
    "    qrel_list (list): A list of TrecQrel objects\n",
    "    topics (list or set, optional): List of topics to consider. If None, all topics are used.\n",
    "    labels (list, optional): List of labels to consider. If None, all labels are used.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary where keys are tuples of qrel object indices and values are confusion matrices\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for (i, qrel1), (j, qrel2) in itertools.combinations(enumerate(qrel_list), 2):\n",
    "        # Compute confusion matrix\n",
    "        conf_matrix = qrel1.check_confusion_matrix(qrel2, topics=topics, labels=labels)\n",
    "        \n",
    "        if conf_matrix is not None:\n",
    "            results[(i, j)] = conf_matrix\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_confusion_matrices(confusion_matrices, qrel_names=None):\n",
    "    \"\"\"\n",
    "    Plot the confusion matrices.\n",
    "    \n",
    "    Args:\n",
    "    confusion_matrices (dict): Output from compute_qrel_confusion_matrices function\n",
    "    qrel_names (list, optional): List of names for the qrel objects. If None, indices will be used.\n",
    "    \"\"\"\n",
    "    n = len(confusion_matrices)\n",
    "    fig, axes = plt.subplots(n, 1, figsize=(10, 8*n), squeeze=False)\n",
    "    \n",
    "    for idx, ((i, j), cm) in enumerate(confusion_matrices.items()):\n",
    "        ax = axes[idx, 0]\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "        \n",
    "        if qrel_names:\n",
    "            title = f'Confusion Matrix: {qrel_names[i]} vs {qrel_names[j]}'\n",
    "        else:\n",
    "            title = f'Confusion Matrix: Qrel {i} vs Qrel {j}'\n",
    "        \n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(qrel_names[j] if qrel_names else j)\n",
    "        ax.set_ylabel(qrel_names[i] if qrel_names else i)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def compute_qrel_comparisons(qrel_list, annotator_names, method='agreement', topics=None):\n",
    "    \"\"\"\n",
    "    Compute agreement or kappa for all combinations of qrel objects in the list.\n",
    "    \n",
    "    Args:\n",
    "    qrel_list (list): A list of TrecQrel objects\n",
    "    annotator_names (list): A list of annotator names corresponding to the qrel objects\n",
    "    method (str): Either 'agreement' or 'kappa'\n",
    "    topics (list or set, optional): List of topics to consider. If None, all topics are used.\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: A DataFrame with comparison results\n",
    "    \"\"\"\n",
    "    if len(qrel_list) != len(annotator_names):\n",
    "        raise ValueError(\"The number of qrel objects must match the number of annotator names\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for (i, qrel1), (j, qrel2) in itertools.product(enumerate(qrel_list), repeat=2):\n",
    "        print((i, j))\n",
    "        if method == 'agreement':\n",
    "            result = qrel1.check_agreement(qrel2, topics=topics)\n",
    "        elif method == 'kappa':\n",
    "            result = qrel1.check_kappa(qrel2)\n",
    "        else:\n",
    "            raise ValueError(\"Method must be either 'agreement' or 'kappa'\")\n",
    "        \n",
    "        if isinstance(result, dict):  # For agreement with multiple topics\n",
    "            for topic, value in result.items():\n",
    "                results.append({\n",
    "                    'Annotator1': annotator_names[i],\n",
    "                    'Annotator2': annotator_names[j],\n",
    "                    'Topic': topic,\n",
    "                    'Value': value\n",
    "                })\n",
    "        else:  # For kappa or agreement without topics\n",
    "            results.append({\n",
    "                'Annotator1': annotator_names[i],\n",
    "                'Annotator2': annotator_names[j],\n",
    "                'Topic': 'All' if topics is None else 'Multiple',\n",
    "                'Value': result\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def plot_comparison_results(comparison_results, method='agreement', out='plots/agreement_all_annotators.svg'):\n",
    "    \"\"\"\n",
    "    Plot the comparison results.\n",
    "    \n",
    "    Args:\n",
    "    comparison_results (pandas.DataFrame): Output from compute_qrel_comparisons function\n",
    "    method (str): Either 'agreement' or 'kappa'\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    if comparison_results['Topic'].nunique() > 1:\n",
    "        sns.boxplot(x='Annotator1', y='Value', hue='Annotator2', data=comparison_results)\n",
    "        plt.title(f'{method.capitalize()} Comparison Across Topics')\n",
    "    else:\n",
    "        sns.barplot(x='Annotator1', y='Value', hue='Annotator2', data=comparison_results)\n",
    "        plt.title(f'Overall {method.capitalize()} Comparison')\n",
    "    \n",
    "    plt.xlabel('Annotator 1')\n",
    "    plt.ylabel(method.capitalize())\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title='Annotator 2', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out, format='svg')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def print_comparison_summary(comparison_results, method='agreement'):\n",
    "    \"\"\"\n",
    "    Print a summary of the comparison results.\n",
    "    \n",
    "    Args:\n",
    "    comparison_results (pandas.DataFrame): Output from compute_qrel_comparisons function\n",
    "    method (str): Either 'agreement' or 'kappa'\n",
    "    \"\"\"\n",
    "    print(f\"\\n{method.capitalize()} Summary:\")\n",
    "    if comparison_results['Topic'].nunique() > 1:\n",
    "        summary = comparison_results.groupby(['Annotator1', 'Annotator2'])['Value'].agg(['mean', 'std', 'min', 'max'])\n",
    "        print(summary)\n",
    "        print(\"\\nOverall Statistics:\")\n",
    "        print(comparison_results['Value'].describe())\n",
    "    else:\n",
    "        print(comparison_results[['Annotator1', 'Annotator2', 'Value']])\n",
    "        print(f\"\\nOverall {method.capitalize()}: {comparison_results['Value'].mean():.4f}\")\n",
    "\n",
    "# Example usage:\n",
    "# qrel_list = [qrel1, qrel2, qrel3]  # List of TrecQrel objects\n",
    "# annotator_names = ['John', 'Alice', 'Bob']  # Names of the annotators\n",
    "# \n",
    "# # For agreement\n",
    "# agreement_results = compute_qrel_comparisons(qrel_list, annotator_names, method='agreement', topics=['301', '302'])\n",
    "# plot_comparison_results(agreement_results, method='agreement')\n",
    "# print_comparison_summary(agreement_results, method='agreement')\n",
    "# \n",
    "# # For kappa\n",
    "# kappa_results = compute_qrel_comparisons(qrel_list, annotator_names, method='kappa')\n",
    "# plot_comparison_results(kappa_results, method='kappa')\n",
    "# print_comparison_summary(kappa_results, method='kappa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#import trectools as tt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset to relevant qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "qids = all_qrels['query_id'].unique()\n",
    "docs_ids = all_qrels['doc_id'].unique()\n",
    "original_qrels_filtered = original_qrels[original_qrels['query_id'].isin(qids)]\n",
    "original_qrels_filtered = original_qrels_filtered[original_qrels_filtered['doc_id'].isin(docs_ids)]\n",
    "tmp_all_qrels = all_qrels[all_qrels['annotator']!= 'ground-truth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_missing_zero_judgments(original_df, new_df):\n",
    "    # Ensure the dataframes have the same column names\n",
    "\n",
    "    # Create a unique identifier for each query-document pair\n",
    "    original_df['pair_id'] = original_df['query_id'] + '_' + original_df['doc_id']\n",
    "    new_df['pair_id'] = new_df['query_id'] + '_' + new_df['doc_id']\n",
    "\n",
    "    # Find original judgments not in new judgments\n",
    "    missing_judgments = original_df[~original_df['pair_id'].isin(new_df['pair_id'])]\n",
    "\n",
    "    # Filter for relevance 0\n",
    "    missing_zero_judgments = missing_judgments[missing_judgments['relevance'] == 0]\n",
    "\n",
    "    # Drop the 'pair_id' column as it's no longer needed\n",
    "    missing_zero_judgments = missing_zero_judgments.drop('pair_id', axis=1)\n",
    "\n",
    "    return missing_zero_judgments\n",
    "missing = find_missing_zero_judgments(original_qrels, tmp_all_qrels)\n",
    "missing['annotator'] = 'original'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_id_map ={\n",
    "    'froebe' : 1,\n",
    "    'ferdinand-schlatt' : 1,\n",
    "    'andrew-parry' : 2,\n",
    "    'eugene-yang' : 2,\n",
    "    'guglielmo-faggioli' : 3,\n",
    "    'harry-scells' : 3,\n",
    "    'saber-zerhoudi' : 4,\n",
    "    'sean-macavaney' : 4\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_all_qrels['group'] = tmp_all_qrels.annotator.map(group_id_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_all_qrels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_qrels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotator Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns histogram of relevance \n",
    "ax = sns.histplot(data=original_qrels_filtered, x='relevance', bins=2)\n",
    "plt.title('Distribution of Original Relevance Judgements in Binary Setting')\n",
    "plt.xlabel('Relevance')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('plots/binary_original_relevance_distribution.svg', format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(original_qrels_filtered))\n",
    "ax = sns.countplot(data=original_qrels_filtered, x='relevance', palette='viridis')\n",
    "ax.set_xlabel('Relevance')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Relevance Distribution of Original Judgments')\n",
    "plt.savefig('plots/original_relevance_distribution.svg', format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_qrels))\n",
    "ax = sns.countplot(data=tmp_all_qrels, x='relevance', palette='viridis')\n",
    "ax.set_xlabel('Relevance')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Relevance Distribution of New Judgments')\n",
    "#plt.savefig('plots/new_relevance_distribution.svg', format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ax = sns.histplot(data=tmp_all_qrels, x='relevance', bins=2)\n",
    "ax.set_title('Distribution of New Judgements in Binary Setting')\n",
    "ax.set_xlabel('Relevance')\n",
    "ax.set_ylabel('Frequency')\n",
    "plt.savefig('plots/binary_new_relevance_distribution.svg', format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.histplot(data=tmp_all_qrels, x='relevance', bins=2, hue='annotator', multiple=\"stack\", palette='viridis')\n",
    "ax.set_title('Relevance distribution for all annotators in binary setting')\n",
    "ax.set_ylabel('Number of documents')\n",
    "ax.set_xlabel('Relevance')\n",
    "plt.savefig('plots/binary_relevance_distribution_all_annotators.svg', format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barplot with exact counts \n",
    "sns.set_context(\"talk\", font_scale=0.8)\n",
    "annotator_rename = {annotator : f'Annotator {i+1}' for i, annotator in enumerate(tmp_all_qrels.annotator.unique().tolist())}\n",
    "print(annotator_rename)\n",
    "tmp_all_qrels['annotator'] = tmp_all_qrels['annotator'].map(annotator_rename)\n",
    "ax = sns.countplot(data=tmp_all_qrels, x='relevance', hue='annotator', palette='viridis')\n",
    "plt.legend(ncol=2)\n",
    "ax.set_ylabel('Number of Documents')\n",
    "ax.set_xlabel('Relevance Grade')\n",
    "plt.subplots_adjust(bottom=0.2) \n",
    "plt.savefig('plots/relevance_distribution_all_annotators.svg', format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_all_qrels['Group'] = tmp_all_qrels['group'].map(lambda x : f'Group {x}')\n",
    "ax = sns.countplot(data=tmp_all_qrels, x='relevance', hue='Group', palette='viridis')\n",
    "ax.set_ylabel('Number of Documents')\n",
    "ax.set_xlabel('Relevance Grade')\n",
    "plt.savefig('plots/relevance_distribution_all_groups.svg', format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_qrels_object = TrecQrel.from_dataframe(original_qrels_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agreement Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = []\n",
    "for a, group in tmp_all_qrels.groupby('annotator'):\n",
    "    new_qrels = TrecQrel.from_dataframe(group)\n",
    "    groups.append(new_qrels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = compute_qrel_comparisons(groups, tmp_all_qrels['annotator'].unique().tolist(), method='agreement')\n",
    "plot_comparison_results(res, method='agreement', out='plots/agreement_all_annotators.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_groups = []\n",
    "for a, group in tmp_all_qrels.groupby('annotator'):\n",
    "    group['relevance'] = group['relevance'].apply(lambda x: 0 if x < 2 else 1)\n",
    "    new_qrels = TrecQrel.from_dataframe(group)\n",
    "    binary_groups.append(new_qrels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = compute_qrel_comparisons(binary_groups, tmp_all_qrels['annotator'].unique().tolist(), method='agreement')\n",
    "plot_comparison_results(res, method='agreement', out='plots/binary_agreement_all_annotators.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ir_measures import * \n",
    "from ir_measures import evaluator\n",
    "import os.path as path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [AP(rel=2), NDCG(cutoff=10), R(rel=2)@100, P(rel=2, cutoff=10), RR(rel=2), RR(rel=2, cutoff=10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_DIR = f'{DIR}/runs/trec-dl-2019'\n",
    "runs = {}\n",
    "for run in os.listdir(RUN_DIR):\n",
    "    frame = pt.io.read_results(path.join(RUN_DIR, run)).rename(columns={'qid': 'query_id', 'docno': 'doc_id'})\n",
    "    frame['pool'] = 'dl-19-official' in run\n",
    "    runs[run] = frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = evaluator(metrics, original_qrels_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orginal_frame = []\n",
    "for run_name, run in runs.items():\n",
    "    results = evaluate.calc_aggregate(run)\n",
    "    results = {str(k) : v for k,v in results.items()}\n",
    "    results['run_name'] = run_name\n",
    "    orginal_frame.append(results)\n",
    "    \n",
    "original_df = pd.DataFrame(orginal_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregated Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = evaluator(metrics, max_qrels)\n",
    "max_frame = []\n",
    "for run_name, run in runs.items():\n",
    "    results = evaluate.calc_aggregate(run)\n",
    "    results = {str(k) : v for k,v in results.items()}\n",
    "    results['run_name'] = run_name\n",
    "    max_frame.append(results)\n",
    "    \n",
    "max_fg = pd.DataFrame(max_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = evaluator(metrics, min_qrels)\n",
    "min_frame = []\n",
    "for run_name, run in runs.items():\n",
    "    results = evaluate.calc_aggregate(run)\n",
    "    results = {str(k) : v for k,v in results.items()}\n",
    "    results['run_name'] = run_name\n",
    "    min_frame.append(results)\n",
    "    \n",
    "min_frame = pd.DataFrame(min_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each Annotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_annotator_frame = []\n",
    "for annotator, qrel in all_qrels.groupby('annotator'):\n",
    "    evaluate = evaluator(metrics, qrel.copy())\n",
    "    for run_name, run in runs.items():\n",
    "        results = evaluate.calc_aggregate(run)\n",
    "        results = {str(k) : v for k,v in results.items()}\n",
    "        results['run_name'] = run_name\n",
    "        results['annotator'] = annotator\n",
    "        each_annotator_frame.append(results)\n",
    "\n",
    "each_annotator_df = pd.DataFrame(each_annotator_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# facetplot over runs, with bars for each metric\n",
    "_each_annotator_df = each_annotator_df[each_annotator_df['annotator'] != 'ground-truth']\n",
    "#g = sns.FacetGrid(_each_annotator_df, col='run_name', col_wrap=3, sharey=True, height=4, aspect=2)\n",
    "# set fig size \n",
    "plt.figure(figsize=(12, 8))\n",
    "g = sns.barplot(_each_annotator_df, x='annotator', y='nDCG@10', hue='run_name', palette='viridis', errwidth=0)\n",
    "plt.xlabel('Annotator')\n",
    "plt.ylabel('nDCG@10')\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig('plots/ndcg10_each_annotator.svg', format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per-Query Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = evaluator(metrics, original_qrels_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orginal_frame = []\n",
    "for run_name, run in runs.items():\n",
    "    for metric in evaluate.iter_calc(run):\n",
    "        result = {'query_id' : metric.query_id, 'run_name' : run_name, 'metric' : str(metric.measure), 'value' : metric.value}\n",
    "        orginal_frame.append(result)\n",
    "original_df = pd.DataFrame(orginal_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Each Annotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_annotator_frame = []\n",
    "for annotator, qrel in all_qrels.groupby('annotator'):\n",
    "    evaluate = evaluator(metrics, qrel.copy())\n",
    "    for run_name, run in runs.items():\n",
    "        for metric in evaluate.iter_calc(run):\n",
    "            result = {'query_id' : metric.query_id, 'run_name' : run_name, 'metric' : str(metric.measure), 'value' : metric.value, 'annotator' : annotator}\n",
    "            each_annotator_frame.append(result)\n",
    "\n",
    "each_annotator_df = pd.DataFrame(each_annotator_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accumulated Annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = evaluator(metrics, accumulated_qrels)\n",
    "\n",
    "accumulated_frame = []\n",
    "\n",
    "for run_name, run in runs.items():\n",
    "    for metric in evaluate.iter_calc(run):\n",
    "        result = {'query_id' : metric.query_id, 'run_name' : run_name, 'metric' : str(metric.measure), 'value' : metric.value}\n",
    "        accumulated_frame.append(result)\n",
    "\n",
    "accumulated_df = pd.DataFrame(accumulated_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_annotator_df.query_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to nDCG@10\n",
    "\n",
    "original_ndcg = original_df[original_df['metric'] == 'nDCG@10']\n",
    "each_annotator_ndcg = each_annotator_df[each_annotator_df['metric'] == 'nDCG@10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with original ndcg\n",
    "\n",
    "each_annotator_ndcg = each_annotator_ndcg.merge(original_ndcg, on=['query_id', 'run_name'], suffixes=('_annotator', '_original'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_annotator_ndcg.query_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_annotator_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot of nDCG@10 for each annotator vs original\n",
    "_each_annotator_ndcg = each_annotator_ndcg[each_annotator_ndcg.annotator != 'ground-truth'].copy()\n",
    "ax = sns.scatterplot(data=_each_annotator_ndcg, x='value_original', y='value_annotator', hue='annotator', palette='viridis')\n",
    "# add line of best fit\n",
    "sns.regplot(data=_each_annotator_ndcg, x='value_original', y='value_annotator', scatter=False)\n",
    "ax.set(xlim=(-0.2, 1.2))\n",
    "ax.set(ylim=(-0.2, 1.2))\n",
    "ax.set_title('nDCG@10 for each annotator vs original')\n",
    "ax.set_xlabel('Original nDCG@10')\n",
    "ax.set_ylabel('Annotator nDCG@10')\n",
    "plt.savefig('plots/ndcg10_each_annotator_vs_original.svg', format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# facets over runs with scatter plot of nDCG@10 for each annotator vs original, increase spacing\n",
    "\n",
    "g = sns.FacetGrid(_each_annotator_ndcg, col='run_name', col_wrap=3, height=4, aspect=1.5)\n",
    "g.map(sns.scatterplot, 'value_original', 'value_annotator', 'annotator', palette='viridis')\n",
    "# add line of best fit\n",
    "g.map(sns.regplot, 'value_original', 'value_annotator', scatter=False)\n",
    "# set x range to be the same for all plots\n",
    "g.set(xlim=(-0.2, 1.2))\n",
    "g.set(ylim=(-0.2, 1.2))\n",
    "g.set_titles('nDCG@10 for each annotator vs original for {col_name}')\n",
    "g.set_xlabels('Original nDCG@10')\n",
    "g.set_ylabels('Annotator nDCG@10')\n",
    "g.add_legend()\n",
    "plt.savefig('plots/ndcg10_each_annotator_vs_original_facets.svg', format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_annotator_ndcg[each_annotator_ndcg['value'] == 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar plot of per query nDCG@10 variance over annotators\n",
    "each_annotator_ndcg = each_annotator_df[each_annotator_df['metric'] == 'nDCG@10'].copy()\n",
    "each_annotator_ndcg['variance'] = each_annotator_ndcg.groupby(['query_id', 'run_name'])['value'].transform('var')\n",
    "ax = sns.barplot(data=each_annotator_ndcg, x='query_id', y='variance', hue='run_name', palette='viridis')\n",
    "ax.set_title('Per query nDCG@10 variance over annotators')\n",
    "ax.set_xlabel('Query ID')\n",
    "ax.set_ylabel('Variance')\n",
    "# rotate x labels\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig('plots/ndcg10_variance_over_annotators.svg', format='svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for qid in each_annotator_ndcg.query_id.unique():\n",
    "    print(qid)\n",
    "    print(query_lookup[int(qid)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
